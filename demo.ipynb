{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio.v3 as io\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from wrappers_matching_utils import geom_verification, plot_imgs, compute_relative_pose, plot_imgs_and_kpts\n",
    "# os.makedirs('md1500_plots', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers_manager import wrappers_manager\n",
    "\n",
    "device = 'cuda'\n",
    "max_kpts = 2048\n",
    "\n",
    "wrapper_engine = 'sift'  # 'superpoint', 'disk', 'dedode', 'strek', 'mix_kpts_descs'\n",
    "wrapper = wrappers_manager(wrapper_engine, device=device)\n",
    "\n",
    "\n",
    "from libutils.utils_matches import MNN\n",
    "matcher = MNN(min_score=0.5, ratio_test=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/home/mattia/Desktop/Repos/megadepth_1500/megadepth_1500') \n",
    "\n",
    "pairs = {\n",
    "    \"easy\"   :{\"scene_name\":'0022_0.5_0.7', 'pair':298},\n",
    "    \"medium\" :{\"scene_name\":'0022_0.3_0.5', 'pair':4},\n",
    "    \"hard\"   :{\"scene_name\":'0022_0.1_0.3', 'pair':3},\n",
    "}\n",
    "pair = pairs['medium']\n",
    "\n",
    "gt_data = np.load(f'{base_path}/{pair[\"scene_name\"]}.npz', allow_pickle=True)\n",
    "\n",
    "id_A = gt_data['pair_infos'][pair['pair']][0][0]\n",
    "id_B = gt_data['pair_infos'][pair['pair']][0][1]\n",
    "im_A_path = gt_data['image_paths'][id_A]\n",
    "im_B_path = gt_data['image_paths'][id_B]\n",
    "\n",
    "print(im_A_path, im_B_path)\n",
    "\n",
    "img_A_np = io.imread(base_path / im_A_path)\n",
    "img_B_np =  io.imread(base_path / im_B_path)\n",
    "x_min = min(img_A_np.shape[0], img_B_np.shape[0])\n",
    "y_min = min(img_A_np.shape[1], img_B_np.shape[1])\n",
    "img_A_np = img_A_np[:x_min, :y_min]\n",
    "img_B_np = img_B_np[:x_min, :y_min]\n",
    "\n",
    "img_A = wrapper.img_from_numpy(img_A_np).to(device)\n",
    "img_B = wrapper.img_from_numpy(img_B_np).to(device)\n",
    "\n",
    "plot_imgs([img_A_np, img_B_np])\n",
    "img_A.shape, img_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libutils_md.geometry import compute_fundamental_from_relative_motion\n",
    "\n",
    "K_A, pose_A = gt_data['intrinsics'][id_A], gt_data['poses'][id_A]\n",
    "K_B, pose_B = gt_data['intrinsics'][id_B], gt_data['poses'][id_B]\n",
    "R_A, t_A = pose_A[:3,:3], pose_A[:3,3]\n",
    "R_B, t_B = pose_B[:3,:3], pose_B[:3,3]\n",
    "\n",
    "R, t = compute_relative_pose(R_A, t_A, R_B, t_B)\n",
    "\n",
    "# scale up\n",
    "import torch.nn.functional as F\n",
    "factor = 1\n",
    "K_A = K_A.copy()\n",
    "K_B = K_B.copy()\n",
    "K_A[:2, :] *= factor\n",
    "K_B[:2, :] *= factor\n",
    "img_A = F.interpolate(img_A.unsqueeze(0), scale_factor=factor, mode='bilinear', align_corners=False).squeeze(0)\n",
    "img_B = F.interpolate(img_B.unsqueeze(0), scale_factor=factor, mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "F_gt = compute_fundamental_from_relative_motion(R, t, K_A, K_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():#, torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "    out1 = wrapper.extract(img_A, max_kpts=max_kpts)\n",
    "    out2 = wrapper.extract(img_B, max_kpts=max_kpts)\n",
    "\n",
    "kpts1, des1 = out1.kpts, out1.des\n",
    "kpts2, des2 = out2.kpts, out2.des\n",
    "print(kpts1.shape, des1.shape, kpts2.shape, des2.shape)\n",
    "\n",
    "matches = matcher.match([des1], [des2])[0].matches\n",
    "kpts1_matched = kpts1[matches[:, 0]].cpu().numpy()\n",
    "kpts2_matched = kpts2[matches[:, 1]].cpu().numpy()\n",
    "print('matched:', kpts1_matched.shape, kpts2_matched.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts1_matched, kpts2_matched, F = geom_verification(kpts1_matched, kpts2_matched, max_iter=1_000_000)\n",
    "\n",
    "plot_imgs_and_kpts(img_A_np, img_B_np, kpts1_matched, kpts2_matched, figsize=(20,10), space=0, matches=True, index=False, pad=True, scatter=False, sample_points=1000, \n",
    "highlight_bad_matches=True, F_gt=F_gt)#, plot_name=f'md1500_plots/{wrapper.name}_{im_A_path.split(\"/\")[-1]}_{im_B_path.split(\"/\")[-1]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extraction with SANDesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/mattia/Desktop/Repos/sandesc')\n",
    "path = f'/home/mattia/Desktop/Repos/sandesc/final_models/{wrapper_engine.split(\"-\")[0]}/final.pth'\n",
    "print('loading model from:', path)\n",
    "\n",
    "weights = torch.load(path,  map_location=device, weights_only=False)\n",
    "config = weights['config']\n",
    "model_config = {'ch_in': config['model_config']['unet_ch_in'],\n",
    "                'kernel_size': config['model_config']['unet_kernel_size'],\n",
    "                'activ': config['model_config']['unet_activ'],\n",
    "                'norm': config['model_config']['unet_norm'],\n",
    "                'skip_connection': config['model_config']['unet_with_skip_connections'],\n",
    "                'spatial_attention': config['model_config']['unet_spatial_attention'],\n",
    "                'third_block': config['model_config']['third_block'],\n",
    "                }\n",
    "print('model config for model.pth:', model_config)\n",
    "\n",
    "from model.network_descriptor import *\n",
    "network = Unet_with_SPATT(**model_config).eval().to(device)\n",
    "\n",
    "network.load_state_dict(weights['state_dict'])\n",
    "wrapper.descriptor_network = network\n",
    "wrapper.add_custom_descriptors(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():#, torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "    out1 = wrapper.extract(img_A, max_kpts=max_kpts)\n",
    "    out2 = wrapper.extract(img_B, max_kpts=max_kpts)\n",
    "\n",
    "kpts1, des1 = out1.kpts, out1.des\n",
    "kpts2, des2 = out2.kpts, out2.des\n",
    "print(kpts1.shape, des1.shape, kpts2.shape, des2.shape)\n",
    "\n",
    "\n",
    "matches = matcher.match([des1], [des2])[0].matches\n",
    "kpts1_matched = kpts1[matches[:, 0]].cpu().numpy()\n",
    "kpts2_matched = kpts2[matches[:, 1]].cpu().numpy()\n",
    "print(kpts1_matched.shape, kpts2_matched.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts1_matched, kpts2_matched, F = geom_verification(kpts1_matched[:-2],kpts2_matched[:-2], max_iter=1_000_000)\n",
    "\n",
    "plot_imgs_and_kpts(img_A_np, img_B_np, kpts1_matched, kpts2_matched, figsize=(20,10), space=0, matches=True, index=False, pad=True, scatter=False, sample_points=1000, \n",
    "highlight_bad_matches=True, F_gt=F_gt, plot_name=f'md1500_plots/{wrapper.name}+sandesc_{im_A_path.split(\"/\")[-1]}_{im_B_path.split(\"/\")[-1]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{wrapper.name}+sandesc_{im_A_path.split(\"/\")[-1]}_{im_B_path.split(\"/\")[-1]}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anydesc_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
